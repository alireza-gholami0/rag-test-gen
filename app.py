import streamlit as st
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import ChatOpenAI
import tempfile
import os

INDEX_PATH = "faiss_index"

# --- 1. Index documents ---
def index_documents(pdf_files):
    docs = []
    for uploaded_file in pdf_files:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
            tmp_file.write(uploaded_file.read())
            loader = PyPDFLoader(tmp_file.name)
            docs += loader.load()

    splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=50)
    chunks = splitter.split_documents(docs)

    embedder = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
    vectordb = FAISS.from_documents(chunks, embedder)
    vectordb.save_local(INDEX_PATH)
    return vectordb, embedder

# --- 2. Create prompt ---
def create_prompt(requirements, ts_description, example_ts=None, example_desc=None):
    example_part = ""
    if example_ts and example_desc:
        example_part = f"""
        Ø³Ù†Ø§Ø±ÛŒÙˆÛŒ ØªØ³Øª Ù†Ù…ÙˆÙ†Ù‡:
        Ø´Ø±Ø­: {example_desc}
        Ù…Ø±Ø§Ø­Ù„:
        {example_ts}
        """

    base_prompt = f"""
    Ø´Ù…Ø§ ÛŒÚ© ØªØ­Ù„ÛŒÙ„â€ŒÚ¯Ø± Ø³ÛŒØ³ØªÙ… Ù‡Ø³ØªÛŒØ¯. ÛŒÚ© Ø³Ù†Ø§Ø±ÛŒÙˆÛŒ ØªØ³Øª Ú¯Ø§Ù…â€ŒØ¨Ù‡â€ŒÚ¯Ø§Ù… Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ù†ÛŒØ§Ø²Ù…Ù†Ø¯ÛŒ Ø²ÛŒØ± Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ ØªÙˆÙ„ÛŒØ¯ Ú©Ù†ÛŒØ¯.
    Ù†ÛŒØ§Ø²Ù…Ù†Ø¯ÛŒâ€ŒÙ‡Ø§:
    {requirements}
    ØªÙˆØ¶ÛŒØ­ Ø³Ù†Ø§Ø±ÛŒÙˆÛŒ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø±:
    {ts_description}
    {example_part}
    Ø¯Ø± Ù†Ù‡Ø§ÛŒØªØŒ Ù„Ø·ÙØ§Ù‹ ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯ Ú©Ù‡ Ú†Ø±Ø§ Ø§ÛŒÙ† Ø³Ù†Ø§Ø±ÛŒÙˆ ØªØ³Øª Ù†ÛŒØ§Ø²Ù…Ù†Ø¯ÛŒ Ø¨Ø§Ù„Ø§ Ø±Ø§ Ù¾ÙˆØ´Ø´ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.
    """
    return base_prompt

# --- 3. Generate test scenario ---
def generate_test_scenario(prompt, vectordb):
    retriever = vectordb.as_retriever(search_kwargs={"k": 3})
    docs = retriever.invoke(prompt)
    context = "\n\n".join([d.page_content for d in docs])

    final_prompt = f"""
    Ù…ØªÙ†â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒâ€ŒØ´Ø¯Ù‡:
    {context}

    Ù¾Ø±Ø³Ø´:
    {prompt}
    """

    llm = ChatOpenAI(
        model='gpt-4o',
        api_key="FAKE",
        base_url="http://localhost:1050/v1",
        temperature=0
    )

    try:
        return llm.invoke(final_prompt)
    except Exception as e:
        return f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Ù…Ø¯Ù„: {e}"
    
# --- 4. Streamlit UI ---
st.set_page_config(page_title="ØªÙˆÙ„ÛŒØ¯ Ø³Ù†Ø§Ø±ÛŒÙˆÛŒ ØªØ³Øª", layout="wide")
st.markdown(
    """
    <style>
    html, body, .main, [data-testid="stAppViewContainer"] {
        direction: rtl !important;
        text-align: right !important;
    }
    </style>
    """,
    unsafe_allow_html=True
)

st.title("ğŸ§ªTest Scenario Generation")

uploaded_pdfs = st.file_uploader(
    "ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ PDF Ø¯Ø§Ù…Ù†Ù‡ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯",
    type="pdf",
    accept_multiple_files=True
)

if st.button("Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ/Ø§ÛŒÙ†Ø¯Ú©Ø³ PDF"):
    if uploaded_pdfs:
        with st.spinner("Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ PDFÙ‡Ø§..."):
            embedder = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
            vectordb, embedder = index_documents(uploaded_pdfs)
            st.success("Ø§ÛŒÙ†Ø¯Ú©Ø³ Ø¬Ø¯ÛŒØ¯ Ø³Ø§Ø®ØªÙ‡ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")
    else:
        st.warning("Ù„Ø·ÙØ§Ù‹ Ø­Ø¯Ø§Ù‚Ù„ ÛŒÚ© PDF Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ù†ÛŒØ¯.")


requirements = st.text_area("Ù†ÛŒØ§Ø²Ù…Ù†Ø¯ÛŒâ€ŒÙ‡Ø§")
description = st.text_area("ØªÙˆØ¶ÛŒØ­ Ø³Ù†Ø§Ø±ÛŒÙˆÛŒ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø±")
example_desc = st.text_area("Ø´Ø±Ø­ Ø³Ù†Ø§Ø±ÛŒÙˆÛŒ Ù†Ù…ÙˆÙ†Ù‡ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)")
example_steps = st.text_area("Ù…Ø±Ø§Ø­Ù„ Ø³Ù†Ø§Ø±ÛŒÙˆÛŒ Ù†Ù…ÙˆÙ†Ù‡ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)")



if st.button("ØªÙˆÙ„ÛŒØ¯ Ø³Ù†Ø§Ø±ÛŒÙˆ"):
    if not os.path.exists(INDEX_PATH):
        st.warning("Ø§Ø¨ØªØ¯Ø§ PDFÙ‡Ø§ Ø±Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ/Ø§ÛŒÙ†Ø¯Ú©Ø³ Ú©Ù†ÛŒØ¯.")
    elif not requirements or not description:
        st.warning("Ù„Ø·ÙØ§Ù‹ Ù†ÛŒØ§Ø²Ù…Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ Ùˆ ØªÙˆØ¶ÛŒØ­ Ø³Ù†Ø§Ø±ÛŒÙˆ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯.")
    else:
        with st.spinner("Ø¯Ø± Ø­Ø§Ù„ ØªÙˆÙ„ÛŒØ¯ Ø³Ù†Ø§Ø±ÛŒÙˆ..."):
            embedder = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
            vectordb = FAISS.load_local(INDEX_PATH, embedder, allow_dangerous_deserialization=True)
            prompt = create_prompt(requirements, description, example_steps, example_desc)
            result = generate_test_scenario(prompt, vectordb)
        st.subheader("Ø³Ù†Ø§Ø±ÛŒÙˆÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡:")
        st.markdown(result.content)
